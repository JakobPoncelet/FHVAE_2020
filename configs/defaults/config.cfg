[RegFHVAE]

# This is a template for a config file

### Model
# options: LSTM_{unidirectional, bidirectional, attention} or transformer
model = LSTM_bidirectional

# latent dimensions
z1_dim = 32
z2_dim = 32

### LSTM architecture
# encoder (hidden units/cells)
z1_rhus = [256, 256]
z2_rhus = [256, 256]
# decoder (hidden units/cells)
x_rhus = [256, 256]

### Transformer architecture
# model dimension
d_model = 256
# number of MHA layers in transformer encoder
num_enc_layers = 8
# number of transformer heads
num_heads = 8
# dimension of inner feedforward layer
dff = 512
# maximum length of positional encoding
pe_max_len = 8000
# dropout rate
rate = 0.1

### Loss factors
# discriminative objective weight
alpha_dis_z1 = 10.0
alpha_dis_z2 = 10.0
# regularization weight on z1
alpha_reg_b = 10.0
# regularization weight on z2
alpha_reg_c = 10.0
# priors: [pz1_stddev, pmu1_stddev, pz2_stddev, pmu2_stddev]
priors = [0.5, 1.0, 0.5, 1.0]

### Training settings
# batch size
batch_size = 256
# number of sequences for hierarchical sampling (2000 for timit, 5000 for others)
nmu2 = 2000
# number of maximum training epochs (timit ~ 2 mins per epoch)
n_epochs = 500
# number of maximum consecutive non-improving epochs
n_patience = 10

### Optimizer settings
# learning rate, can be fixed e.g. '0.001' or 'custom' (for transformer model)
lr = 0.001
# number of warm up steps when using custom learning rate (lr will steeply rise until step=warmup, and slowly degrade afterwards)
warmup_steps = 4000
# epsilon parameter of adam
adam_eps = 1.0e-8
# memory factors
beta1 = 0.95
beta2 = 0.999

### Regularizing training factors
# list of regularizing training factors, timit: gender/region/spk, cgn: gender/reg1/reg2/reg3/comp/spk
facs = gender:region:spk
# list of regularizing training factors that are time aligned, timit: phones/class1/class2, cgn: phones
talabs = phones:class1:class2
# locations of factor files (as created with the example scripts)
fac_root = /esat/spchdisk/scratch/jponcele/fhvae_jakob/datasets/timit_np_fbank_3/fac/all_facs_%s.scp

### Data locations
# which dataset to use for training (timit_np_fbank_2 = 61 phones, *_*_3 = 39 phones)
dataset = timit_np_fbank_3
# where the dataset is stored, one higher than dataset above (will be linked to ./datasets)
datadir = /esat/spchdisk/scratch/jponcele/fhvae_jakob/datasets

### Configurations for testing
# name of dataset to evaluate on (testing on different dataset is still experimental!!)
dataset_test = timit_np_fbank
# name of dataset partition to evaluate, e.g. dev or test
set_name = test
